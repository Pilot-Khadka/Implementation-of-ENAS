{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural architecture Search using One shot NAS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d476ba14e2ba1f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('DATASETS/wine-quality.csv')\n",
    "x = data.drop('quality_label', axis=1, inplace=False).values\n",
    "print(x.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:17.347947219Z",
     "start_time": "2023-11-20T14:10:17.041062540Z"
    }
   },
   "id": "846c3589311636cc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'type': 'hidden', 'nodes': 8, 'activation': 'Sigmoid'}, 2: {'type': 'hidden', 'nodes': 8, 'activation': 'Tanh'}, 3: {'type': 'hidden', 'nodes': 8, 'activation': 'ReLU'}, 4: {'type': 'hidden', 'nodes': 16, 'activation': 'Sigmoid'}, 5: {'type': 'hidden', 'nodes': 16, 'activation': 'Tanh'}, 6: {'type': 'hidden', 'nodes': 16, 'activation': 'ReLU'}, 7: {'type': 'hidden', 'nodes': 32, 'activation': 'Sigmoid'}, 8: {'type': 'hidden', 'nodes': 32, 'activation': 'Tanh'}, 9: {'type': 'hidden', 'nodes': 32, 'activation': 'ReLU'}, 10: {'type': 'hidden', 'nodes': 64, 'activation': 'Sigmoid'}, 11: {'type': 'hidden', 'nodes': 64, 'activation': 'Tanh'}, 12: {'type': 'hidden', 'nodes': 64, 'activation': 'ReLU'}, 13: {'type': 'hidden', 'nodes': 128, 'activation': 'Sigmoid'}, 14: {'type': 'hidden', 'nodes': 128, 'activation': 'Tanh'}, 15: {'type': 'hidden', 'nodes': 128, 'activation': 'ReLU'}, 16: {'type': 'hidden', 'nodes': 256, 'activation': 'Sigmoid'}, 17: {'type': 'hidden', 'nodes': 256, 'activation': 'Tanh'}, 18: {'type': 'hidden', 'nodes': 256, 'activation': 'ReLU'}, 19: {'type': 'hidden', 'nodes': 512, 'activation': 'Sigmoid'}, 20: {'type': 'hidden', 'nodes': 512, 'activation': 'Tanh'}, 21: {'type': 'hidden', 'nodes': 512, 'activation': 'ReLU'}, 22: {'type': 'dropout'}, 23: {'type': 'output', 'nodes': 3, 'activation': 'Softmax'}}\n",
      "Size of vocabulary: 23\n"
     ]
    }
   ],
   "source": [
    "from parameters import *\n",
    "\n",
    "def vocab_dict():\n",
    "    vocab = {}\n",
    "    layer_id = 1\n",
    "\n",
    "    for node in nodes:\n",
    "        for activation in activations:\n",
    "            vocab[layer_id] = {'type': 'hidden', 'nodes': node, 'activation': activation}\n",
    "            layer_id += 1\n",
    "\n",
    "    vocab[layer_id] = {'type': 'dropout'}\n",
    "    layer_id += 1\n",
    "\n",
    "    output_activation = 'Sigmoid' if target_classes == 2 else 'Softmax'\n",
    "    vocab[layer_id] = {'type': 'output', 'nodes': target_classes, 'activation': output_activation}\n",
    "\n",
    "    return vocab\n",
    "\n",
    "encoded = vocab_dict()\n",
    "print(encoded)\n",
    "print('Size of vocabulary:',len(encoded))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:18.784453302Z",
     "start_time": "2023-11-20T14:10:18.764350016Z"
    }
   },
   "id": "dfd73ec6391825cc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab ids: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "vocab_idx = list(encoded.keys())\n",
    "print('vocab ids:',vocab_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:19.062594218Z",
     "start_time": "2023-11-20T14:10:19.041278539Z"
    }
   },
   "id": "b6f00d49734a98dd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size , output_size ):\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size ,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=2) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out,_ = self.lstm(x)\n",
    "        x = self.fc(lstm_out)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:21.451737181Z",
     "start_time": "2023-11-20T14:10:19.306666729Z"
    }
   },
   "id": "65ed91f2f2cfa201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([1, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "seed = torch.zeros(max_len-1)\n",
    "print(seed)\n",
    "inputs = seed.reshape(1,1,9)\n",
    "print(inputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:21.464668983Z",
     "start_time": "2023-11-20T14:10:21.455837276Z"
    }
   },
   "id": "f4bf42a69fd42af3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m sequence \u001B[38;5;241m=\u001B[39m pad_sequence([torch\u001B[38;5;241m.\u001B[39mtensor(seed)], batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, padding_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Batch_size, sequence_length, feature_dimension\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m sequence \u001B[38;5;241m=\u001B[39m \u001B[43msequence\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43mmax_len\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Adjust the dimensions\u001B[39;00m\n\u001B[1;32m      5\u001B[0m sequence \u001B[38;5;241m=\u001B[39m sequence\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(sequence)\n",
      "\u001B[0;31mIndexError\u001B[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "seed=[]\n",
    "sequence = pad_sequence([torch.tensor(seed)], batch_first=True, padding_value=0)\n",
    "# Batch_size, sequence_length, feature_dimension\n",
    "sequence = sequence[:, :max_len-1, :]  # Adjust the dimensions\n",
    "sequence = sequence.unsqueeze(1)\n",
    "print(sequence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:21.787233691Z",
     "start_time": "2023-11-20T14:10:21.504275608Z"
    }
   },
   "id": "5bc5058aa347da04"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 23])\n",
      "tensor([[[0.0403, 0.0453, 0.0467, 0.0464, 0.0397, 0.0424, 0.0458, 0.0421,\n",
      "          0.0412, 0.0469, 0.0439, 0.0469, 0.0434, 0.0417, 0.0454, 0.0452,\n",
      "          0.0438, 0.0415, 0.0404, 0.0400, 0.0396, 0.0467, 0.0446]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "model = LSTM(input_size=max_len-1,hidden_size=100,output_size = len(vocab_idx))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.005)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(inputs) \n",
    "    print(output.shape)\n",
    "    print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:22.558259830Z",
     "start_time": "2023-11-20T14:10:22.233751688Z"
    }
   },
   "id": "65ad2ed0755976f3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0403, 0.0453, 0.0467, 0.0464, 0.0397, 0.0424, 0.0458, 0.0421, 0.0412,\n",
      "        0.0469, 0.0439, 0.0469, 0.0434, 0.0417, 0.0454, 0.0452, 0.0438, 0.0415,\n",
      "        0.0404, 0.0400, 0.0396, 0.0467, 0.0446])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(output[0][0])\n",
    "print(torch.sum(output[0][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:22.571342770Z",
     "start_time": "2023-11-20T14:10:22.560123154Z"
    }
   },
   "id": "7a03b623ba21ab90"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# next = np.random.choice(vocab_idx,p=output[0][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:23.205197604Z",
     "start_time": "2023-11-20T14:10:23.200761078Z"
    }
   },
   "id": "fe157383336c7a45"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# probab = output[0][0]\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# probab = probab / torch.sum(probab)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# probab = probab.squeeze().tolist()\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mnext\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mnext\u001B[39m)\n",
      "File \u001B[0;32mmtrand.pyx:958\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# probab = output[0][0]\n",
    "# probab = probab / torch.sum(probab)\n",
    "# probab = probab.squeeze().tolist()\n",
    "next = np.random.choice(vocab_idx,p=output[0][0])\n",
    "\n",
    "print(next)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:23.727226089Z",
     "start_time": "2023-11-20T14:10:23.692590424Z"
    }
   },
   "id": "a86872e6e28945b7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocab: 23\n",
      "Length of vocab: 23\n",
      "Final elemenet :  23\n"
     ]
    }
   ],
   "source": [
    "print('length of vocab:',len(vocab_idx))\n",
    "print('Length of vocab:',vocab_idx[-1])\n",
    "print('Final elemenet : ', vocab_idx[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:24.464789914Z",
     "start_time": "2023-11-20T14:10:24.446862917Z"
    }
   },
   "id": "60af3c418cf9b673"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab before adding final layer: 9\n",
      "Final layer id: 23\n",
      "Final architecture:  [14, 2, 20, 14, 3, 20, 1, 15, 15, 23]\n"
     ]
    }
   ],
   "source": [
    "seed = []\n",
    "\n",
    "while len(seed) < max_len-1:\n",
    "    # print(seed)\n",
    "    sequence = torch.zeros(max_len-1)\n",
    "    sequence = sequence.reshape(1,1,max_len-1)\n",
    "    # print(sequence.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probab = model(sequence)\n",
    "    \n",
    "    probab = np.array(probab)\n",
    "    \n",
    "    # print(probab[0][0])\n",
    "    # print(probab[0][0].sum())    \n",
    "    \n",
    "    normalized_probab = probab / probab.sum()\n",
    "    next = np.random.choice(vocab_idx,p=normalized_probab[0][0])\n",
    "    if next == len(vocab_idx):\n",
    "        break\n",
    "    seed.append(next)\n",
    "\n",
    "print('Length of vocab before adding final layer:',len(seed))\n",
    "print('Final layer id:',len(vocab_idx))\n",
    "seed.append(len(vocab_idx))\n",
    "print('Final architecture: ',seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:25.806773999Z",
     "start_time": "2023-11-20T14:10:25.782393079Z"
    }
   },
   "id": "e3f96819df7a7a04"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# print(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T02:39:20.448390234Z",
     "start_time": "2023-11-18T02:39:20.438514449Z"
    }
   },
   "id": "a2697d5b87461d0d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# from parameters import *\n",
    "# \n",
    "# import torch\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# seed = []\n",
    "# seed = torch.zeros(max_len-1)\n",
    "# sequence = seed.reshape(1,1,max_len-1)\n",
    "# print(sequence.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T02:39:20.994796639Z",
     "start_time": "2023-11-18T02:39:20.979720984Z"
    }
   },
   "id": "fd83ebd566baea51"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'hidden', 'nodes': 128, 'activation': 'Tanh'}, {'type': 'hidden', 'nodes': 8, 'activation': 'Tanh'}, {'type': 'hidden', 'nodes': 512, 'activation': 'Tanh'}, {'type': 'hidden', 'nodes': 128, 'activation': 'Tanh'}, {'type': 'hidden', 'nodes': 8, 'activation': 'ReLU'}, {'type': 'hidden', 'nodes': 512, 'activation': 'Tanh'}, {'type': 'hidden', 'nodes': 8, 'activation': 'Sigmoid'}, {'type': 'hidden', 'nodes': 128, 'activation': 'ReLU'}, {'type': 'hidden', 'nodes': 128, 'activation': 'ReLU'}, {'type': 'output', 'nodes': 3, 'activation': 'Softmax'}]\n"
     ]
    }
   ],
   "source": [
    "## Next step is to convert the encoded architecture back to form where we understand what each layer mean\n",
    "\n",
    "def decode_architecture(sequence):\n",
    "    seed = []\n",
    "    for _ in sequence:\n",
    "        original_param = encoded[_]\n",
    "        seed.append(original_param)\n",
    "    \n",
    "    # print(original_param)\n",
    "    return seed\n",
    "\n",
    "decoded = decode_architecture(seed)\n",
    "print(decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:29.913116489Z",
     "start_time": "2023-11-20T14:10:29.896522712Z"
    }
   },
   "id": "61926fbb5cf907ef"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (layers): Sequential(\n",
      "    (linear0): Linear(in_features=10, out_features=128, bias=True)\n",
      "    (activation0): Tanh()\n",
      "    (linear1): Linear(in_features=128, out_features=8, bias=True)\n",
      "    (activation1): Tanh()\n",
      "    (linear2): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (activation2): Tanh()\n",
      "    (linear3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (activation3): Tanh()\n",
      "    (linear4): Linear(in_features=128, out_features=8, bias=True)\n",
      "    (activation4): ReLU()\n",
      "    (linear5): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (activation5): Tanh()\n",
      "    (linear6): Linear(in_features=512, out_features=8, bias=True)\n",
      "    (activation6): Sigmoid()\n",
      "    (linear7): Linear(in_features=8, out_features=128, bias=True)\n",
      "    (activation7): ReLU()\n",
      "    (linear8): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (activation8): ReLU()\n",
      "    (linear9): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (activation9): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pilot/miniconda3/envs/jupyter/lib/python3.8/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from torchviz import make_dot\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, mlp_input_shape, mlp_dropout,sequence):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.mlp_input_shape = mlp_input_shape\n",
    "        self.mlp_dropout = mlp_dropout\n",
    "\n",
    "        # Initialize layers in __init__ method\n",
    "        self.layers = self.initialize_layers(sequence)\n",
    "\n",
    "    def initialize_layers(self,sequence):\n",
    "        layer_configs = decode_architecture(sequence)  # Assuming you have a method to decode the sequence\n",
    "        layers = []\n",
    "        prev_nodes = []\n",
    "        \n",
    "        if len(self.mlp_input_shape) > 1:\n",
    "            layers.append(nn.Flatten())\n",
    "\n",
    "        for i, layer_conf in enumerate(layer_configs):\n",
    "            # print(i,layer_conf)\n",
    "            if layer_conf['type'] == 'dropout':\n",
    "                layers.append(('dropout{}'.format(i), nn.Dropout(self.mlp_dropout)))\n",
    "            else:\n",
    "                activation = getattr(nn, layer_conf['activation'])() if layer_conf['activation'] else None\n",
    "                # print(activation)\n",
    "                \n",
    "                if i == 0:\n",
    "                    linear_layer = nn.Linear(self.mlp_input_shape[0],layer_conf['nodes'])\n",
    "                    prev_nodes = layer_conf['nodes']\n",
    "                else:\n",
    "                    # print(self.mlp_input_shape.shape())\n",
    "                    linear_layer = nn.Linear(prev_nodes, layer_conf['nodes'])\n",
    "                    prev_nodes = layer_conf['nodes']\n",
    "                    \n",
    "                layers.append(('linear{}'.format(i), linear_layer))\n",
    "                if activation:\n",
    "                    layers.append(('activation{}'.format(i), activation))\n",
    "        # print(layers)\n",
    "        return nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Example usage:\n",
    "mlp_input_shape = (10,)  # Example input shape\n",
    "mlp_dropout = 0.5  # Example dropout rate\n",
    "\n",
    "# Create an instance of the model\n",
    "\n",
    "input_tensor = torch.randn((0,) + mlp_input_shape)\n",
    "# print(input_tensor.shape)\n",
    "custom_model = CustomModel(mlp_input_shape, mlp_dropout,seed)\n",
    "\n",
    "# Create a random input tensor for testing\n",
    "\n",
    "# Forward pass\n",
    "output_tensor = custom_model(input_tensor)\n",
    "\n",
    "# Print the model architecture\n",
    "print(custom_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:10:34.802590054Z",
     "start_time": "2023-11-20T14:10:34.682103112Z"
    }
   },
   "id": "8fa57d9755184d1c"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# make_dot(output, params=dict(custom_model.named_parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:00.599434771Z",
     "start_time": "2023-11-18T03:25:00.591201083Z"
    }
   },
   "id": "6400815c372696c8"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "## Train the model\n",
    "def train_model (model, x,y):\n",
    "    history = model.fit(x,y)\n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:01.670982367Z",
     "start_time": "2023-11-18T03:25:01.651742188Z"
    }
   },
   "id": "31458a2538ec91cf"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:02.617915821Z",
     "start_time": "2023-11-18T03:25:02.580721956Z"
    }
   },
   "id": "b4535cb8949a3869"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:03.776505141Z",
     "start_time": "2023-11-18T03:25:03.739792348Z"
    }
   },
   "id": "cefada5d40c57e0d"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:03.964953796Z",
     "start_time": "2023-11-18T03:25:03.926510105Z"
    }
   },
   "id": "ed0610adc73fc5ca"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T03:25:04.098869648Z",
     "start_time": "2023-11-18T03:25:04.052419955Z"
    }
   },
   "id": "40c9de1720712056"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c7aaf9e83c7535fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
